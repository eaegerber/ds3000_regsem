{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e74574",
   "metadata": {},
   "source": [
    "# DS3000 Day 9\n",
    "\n",
    "Oct 11 2022\n",
    "\n",
    "Admin:\n",
    "- due Tonight before midnight\n",
    "    - hw3\n",
    "    - Project Proposals\n",
    "        - Check Canvas for an example Data Analysis Plan\n",
    "- lab on Friday (no lecture; maybe visitor)\n",
    "- hw4 will be posted by the end of today, due next Tuesday before midnight\n",
    "\n",
    "Content:\n",
    "- Continue Intro to Web Scraping/DS Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa015acb",
   "metadata": {},
   "source": [
    "### Previously on DS 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9f288",
   "metadata": {},
   "source": [
    "## Beginning the pipeline\n",
    "\n",
    "**Goal:** Get a list of recipe names from www.allrecipes.com like we did for:\n",
    "\n",
    "https://www.allrecipes.com/search?q=cheese+fondue\n",
    "\n",
    "1. Write function `crawl_recipes(query)` which:\n",
    "    * takes the search phrase (the ingredient) as input argument\n",
    "    * builds the correct url that leads directly to the page that lists the recipes\n",
    "    * uses `requests` to get the content of this page returns the html text of the page\n",
    "1. Write `extract_recipes(text)` which:\n",
    "    * takes the text returned by `crawl_recipes` as argument\n",
    "    * builds a BeautifulSoup object out of that text \n",
    "    * finds names of all recipes\n",
    "        - to identify which tags / classes to `find_all()`, open the page in your browser and \"inspect\" \n",
    "        - start from the recipe object above, and call another `find_all()` to zoom into the recipe name itself\n",
    "    * returns the list of recipe names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58286cdd",
   "metadata": {},
   "source": [
    "A new function that will help if you wish to query multiple words:\n",
    "\n",
    "`string.replace()`\n",
    "\n",
    "So, if you wish to turn `cheese fondue` into `cheese+fondue`:\n",
    "\n",
    "`string = 'cheese fondue'`\n",
    "\n",
    "`string.replace(\" \", \"+\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cebce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_recipes(query):\n",
    "    \"\"\" gets html of from allrecipes.com to search query\n",
    "    \n",
    "    Args:\n",
    "        query (str): search string\n",
    "        \n",
    "    Returns:\n",
    "        html_str (str): html response from allreceipes.com\n",
    "    \"\"\"\n",
    "    \n",
    "    query = query.replace(\" \", \"+\")\n",
    "    url = f'https://www.allrecipes.com/search?q={query}'\n",
    "    return requests.get(url).text\n",
    "\n",
    "def extract_recipes(text):\n",
    "    \"\"\" builds list of recipe names from allrecipies html\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html response from allrecipes.com, see crawl_recipes()\n",
    "        \n",
    "    Returns:\n",
    "        recipe_list (list): list of recipes\n",
    "    \"\"\"\n",
    "    # build soup object from text\n",
    "    soup = BeautifulSoup(text)\n",
    "    \n",
    "    \n",
    "    recipe_list = []\n",
    "    for recipe in soup.find_all(class_='card__title-text'):\n",
    "        # extract / store recipe\n",
    "        recipe = recipe.text\n",
    "        recipe_list.append(recipe)\n",
    "    return recipe_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheesefondue_html = crawl_recipes('cheese fondue')\n",
    "recipe_list = extract_recipes(cheesefondue_html)\n",
    "recipe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb35d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "meatloaf_html = crawl_recipes('meatloaf')\n",
    "new_recipe_list = extract_recipes(meatloaf_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8785b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recipe_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c572fa",
   "metadata": {},
   "source": [
    "## Getting info from each recipe's own page:\n",
    "\n",
    "When we interact with the webpage in the browser, clicking on the header with the recipe name leads us to the actual recipe. Let's have a look at how it's done. Here is the link (`<a >` tag) for the first and third cards of the meatloaf search:\n",
    "\n",
    "```html\n",
    "<a class=\"comp mntl-card-list-items mntl-document-card mntl-card card card--no-image\" \n",
    "   data-cta=\"\" \n",
    "   data-doc-id=\"6663943\" \n",
    "   data-ordinal=\"1\" \n",
    "   data-tax-levels=\"\" \n",
    "   href=\"https://www.allrecipes.com/recipe/219171/classic-meatloaf/\" \n",
    "   id=\"mntl-card-list-items_1-0\">\n",
    "```\n",
    "\n",
    "```html\n",
    "<a class=\"comp mntl-card-list-items mntl-document-card mntl-card card card--no-image\" \n",
    "   data-cta=\"\" \n",
    "   data-doc-id=\"6663443\" \n",
    "   data-ordinal=\"3\" \n",
    "   data-tax-levels=\"\" \n",
    "   href=\"https://www.allrecipes.com/recipe/223381/melt-in-your-mouth-meat-loaf/\" \n",
    "   id=\"mntl-card-list-items_1-0-2\">\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meatloaf_html = crawl_recipes('meatloaf')\n",
    "soup = BeautifulSoup(meatloaf_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single recipe with link\n",
    "recipe = soup.find_all('a', class_='comp mntl-card-list-items mntl-document-card mntl-card card card--no-image')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdd460",
   "metadata": {},
   "source": [
    "`BeautifulSoup` exposes a tag's attributes as a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe.attrs['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708223b",
   "metadata": {},
   "source": [
    "# Adding `href` to our dataframe of recipes\n",
    "\n",
    "Let's modify our `extract_recipes()` function such that rather than returning just the names of the dishes, it returns a list of dictionaries, where each dictionary has the `name` and `url` fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db156b03",
   "metadata": {},
   "source": [
    "## `from_dict`\n",
    "\n",
    "First, a useful tool to turn a dictionary into a data frame where the keys are features (columns) and the values are lists that correspond to the values of the features (rows) is the `pd.DataFrame.from_dict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ebfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dict = {'col1': [1,2,3,4,5],\n",
    "                'col2': [6,7,8,9,10],\n",
    "                'col3': ['who', 'what', 'when', 'where', 'why']}\n",
    "pd.DataFrame.from_dict(example_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a507278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recipes(text):\n",
    "    \"\"\" builds list of recipe names from allrecipies html\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html response from allrecipes.com, see crawl_recipes()\n",
    "        \n",
    "    Returns:\n",
    "        df_recipe (pd.DataFrame): dataframe of recipes\n",
    "    \"\"\"\n",
    "    # build soup object from text\n",
    "    soup = BeautifulSoup(text)\n",
    "    \n",
    "    recipe_list = []\n",
    "    for recipe in soup.find_all(class_='card__title-text'):\n",
    "        # extract / store recipe\n",
    "        recipe_name = recipe.text\n",
    "        recipe_list.append(recipe_name)\n",
    "\n",
    "    href_list = []\n",
    "    for recipe in soup.find_all('a', class_='comp mntl-card-list-items mntl-document-card mntl-card card card--no-image'):\n",
    "        # grab the link from each recipe\n",
    "        recipe_link = recipe.attrs['href']\n",
    "        href_list.append(recipe_link)\n",
    "        \n",
    "        \n",
    "    # bundle as a dictionary (then use from_dict)\n",
    "    recipe_dict = {'name': recipe_list,\n",
    "                   'href': href_list}\n",
    "    df_recipe = pd.DataFrame.from_dict(recipe_dict)\n",
    "        \n",
    "    return df_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_recipes(meatloaf_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ace46",
   "metadata": {},
   "source": [
    "## String Manipulations\n",
    "- `.split()` & `.join()`\n",
    "- `.strip()`\n",
    "- `.replace()`\n",
    "- `.upper()` & `.lower()`\n",
    "\n",
    "Visting [a specific recipe's page](https://www.allrecipes.com/recipe/219171/classic-meatloaf/) yields data stored in a string.  The methods above allow us to extract this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f99099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .strip removes all leading and trailing whitespace (spaces and newlines)\n",
    "'\\n\\n\\n hello!      \\n    hello! \\n\\n    \\n \\n'.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we saw .replace last class:\n",
    "'cheese fondue'.replace(' ', '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hello fred\".replace(\"fred\", \"george\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77835005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use replace to delete parts of the string\n",
    "'lets forget about it, okay?'.replace(' it', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f071135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capitalize everything\n",
    "'dont shout!'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbdde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase everything\n",
    "'BE QuieT'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e632b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split will split a string on every occurance of given string (',' below)\n",
    "'fat: 54 g, calories: 430 cal, sugar: 10g'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put disparate strings into a single string, glued together by some other string\n",
    "'<glue>'.join(['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f487c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20515cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = 'last0, first0, last1, first1, last2, first2'.split(',')\n",
    "\n",
    "','.join(name_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(name_list[2:4]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit specific recipe's page\n",
    "url = 'https://www.allrecipes.com/recipe/283561/classic-cheese-fondue/'\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa96ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prep info from 'mntl-recipe-details__content'\n",
    "info_str = soup.find_all(class_='mntl-recipe-details__content')[0].text.strip().replace('\\n', ' ')\n",
    "info_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6e4d9",
   "metadata": {},
   "source": [
    "As a string, this isn't as useful, we'd like to transform it into a dictionary:\n",
    "\n",
    "```python\n",
    "prep_info_dict = {'Prep Time': '10 mins',\n",
    "                  'Cook Time': '15 mins',\n",
    "                  'Total Time': '25 mins',\n",
    "                  'Servings': '10',\n",
    "                  'Yield': '10 servings'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdffb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting nutrition informatin\n",
    "# after some crawling we can find the labels here\n",
    "soup.find_all('span', class_ = 'mntl-nutrition-facts-label__nutrient-name mntl-nutrition-facts-label__nutrient-name--has-postfix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260dcbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the values can be found using the .next_sibling attribute\n",
    "soup.find_all('span', class_ = 'mntl-nutrition-facts-label__nutrient-name mntl-nutrition-facts-label__nutrient-name--has-postfix')[0].next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f02285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting nutrition information\n",
    "nutr_dict = dict()\n",
    "nutr_list = soup.find_all('span', class_ = 'mntl-nutrition-facts-label__nutrient-name mntl-nutrition-facts-label__nutrient-name--has-postfix')\n",
    "for fact in nutr_list:\n",
    "    nutr_dict[fact.text] = fact.next_sibling.strip()\n",
    "    \n",
    "nutr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f58da7",
   "metadata": {},
   "source": [
    "## Lecture Break/Practice\n",
    "Write two functions: `extract_prep_info()` and `extract_nutrition()`, which both accept a url of a particular recipe (see examples above) and return dictionaries of the prep in of nutritional information, respectively. For example:\n",
    "\n",
    "```python\n",
    "url = 'https://www.allrecipes.com/recipe/283561/classic-cheese-fondue/'\n",
    "extract_prep_info(url)\n",
    "extract_nutrition(url)\n",
    "\n",
    "```\n",
    "\n",
    "yields:\n",
    "\n",
    "```python\n",
    "prep_info_dict = {'Prep Time': '10 mins',\n",
    "                  'Cook Time': '15 mins',\n",
    "                  'Total Time': '25 mins',\n",
    "                  'Servings': '10',\n",
    "                  'Yield': '10 servings'}\n",
    "\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "nutr_info_dict = {'Total Fat': '14g',\n",
    "                  'Saturated Fat': '9g',\n",
    "                  'Cholesterol': '46mg',\n",
    "                  'Sodium': '179mg',\n",
    "                  'Total Carbohydrate': '3g',\n",
    "                  'Total Sugars': '1g',\n",
    "                  'Protein': '13g',\n",
    "                  'Vitamin C': '0mg',\n",
    "                  'Calcium': '461mg',\n",
    "                  'Iron': '0mg',\n",
    "                  'Potassium': '67mg'}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a719fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_str.split(\"   \")[0].split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32978050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prep_info(url):\n",
    "    \"\"\" returns a dictionary of recipe preparation info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        prep_info_dict (dict): keys are features ('prep'), \n",
    "            vals are str that describe feature ('20 mins')\n",
    "    \"\"\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    prep_str = soup.find_all(class_='mntl-recipe-details__content')[0].text.strip().replace('\\n', ' ')\n",
    "    prep_dict = dict()\n",
    "    \n",
    "    for line in prep_str.split('   '):\n",
    "        line_list = line.split(':')\n",
    "        prep_dict[line_list[0].strip()] = line_list[1].strip()\n",
    "    \n",
    "    return prep_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nutrition(url):\n",
    "    \"\"\" returns a dictionary of nutrition info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        nutr_dict (dict): keys are molecule types ('fat'), \n",
    "            vals are str of quantity ('24 g')\n",
    "    \"\"\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    nutr_dict = dict()\n",
    "    nutr_list = soup.find_all('span', class_ = 'mntl-nutrition-facts-label__nutrient-name mntl-nutrition-facts-label__nutrient-name--has-postfix')\n",
    "    for fact in nutr_list:\n",
    "        nutr_dict[fact.text] = fact.next_sibling.strip()\n",
    "    \n",
    "    return nutr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allrecipes.com/recipe/283561/classic-cheese-fondue/'\n",
    "extract_prep_info(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee51b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_nutrition(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1bdf54",
   "metadata": {},
   "source": [
    "### Grabbing numeric values (float/int) from messy strings\n",
    "\n",
    "- We have strings which describe recipe nutrition info (`'100 mg'`)\n",
    "- We want numeric data types (`float, int`) so that we can plot and operate on these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf39369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float from string\n",
    "float('123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff968ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential problem when dealing with a full string: replacing g also modifies sugar\n",
    "nutr_val = 'sugars: 40 g'\n",
    "nutr_val.replace('g', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65414f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endswith is a method of strings.  allows us to test if a string ends with another string\n",
    "s = 'youll never guess whats last'\n",
    "s.endswith('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# startswith does the same for the beggining of the string\n",
    "s = 'hello asdf!'\n",
    "s.startswith('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af378873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the unit in the example above\n",
    "nutr_val = 'sugars: 40 g'\n",
    "\n",
    "if nutr_val.endswith('g'):\n",
    "    # reset nutr_val to exclude this last values\n",
    "    nutr_val = nutr_val[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the unit in the example above (programmatically)\n",
    "nutr_val = 'sugars: 40 g'\n",
    "s_remove = 'g'\n",
    "if nutr_val.endswith(s_remove):\n",
    "    nutr_val = nutr_val[:-len(s_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing many units in a loop\n",
    "nutr_val = 'sugars: 40 Grams'\n",
    "for s_rm in ['Grams', 'mg', 'g']:\n",
    "    if nutr_val.endswith(s_rm):\n",
    "        nutr_val = nutr_val[:-len(s_rm)]\n",
    "\n",
    "nutr_val.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e7139",
   "metadata": {},
   "source": [
    "## Rest of Class (Go slowly; if we don't finish we can next week)\n",
    "Complete the `extract_nutrition()` below such that:\n",
    "\n",
    "```python\n",
    "# get / extract a data frame of recipes (only name and href)\n",
    "str_query = 'boston cream pie'\n",
    "html_str = crawl_recipes(str_query)\n",
    "df_recipe = extract_recipes(html_str)\n",
    "\n",
    "for row_idx in range(df_recipe.shape[0]):\n",
    "    # get / extract nutrition info for a particular recipe\n",
    "    recipe_url = df_recipe.loc[row_idx, 'href']\n",
    "    nutr_dict = extract_nutrition(recipe_url)\n",
    "    \n",
    "    # add each new nutrition feature to the dataframe\n",
    "    # only if there ARE nutrition features\n",
    "    if len(nutr_dict) != 0:\n",
    "        for nutr_feat, nutr_val in nutr_dict.items():\n",
    "            df_recipe.loc[row_idx, nutr_feat] = nutr_val\n",
    "    else:\n",
    "        df_recipe = df_recipe.drop(row_idx, axis=0)\n",
    "\n",
    "```\n",
    "\n",
    "generates the `df_recipe`:\n",
    "\n",
    "|    | name                           | href                                              | Total Fat | Saturated Fat | Cholesterol | Sodium | Total Carbohydrate | Dietary Fiber | Total Sugars | Protein | Vitamin C | Calcium | Iron | Potassium |\n",
    "|----|--------------------------------|---------------------------------------------------|-----------|---------------|-------------|--------|--------------------|---------------|--------------|---------|-----------|---------|------|-----------|\n",
    "| 0  | Chef John's Boston Cream Pie   | https://www.allrecipes.com/recipe/220942/chef-... | 41        | 17            | 199         | 514    | 72                 | 2             | 46           | 10      | 0         | 168     | 2    | 230       |\n",
    "| 1  | Boston Cream Pie               | https://www.allrecipes.com/recipe/8138/boston-... | 13        | 6             | 61          | 230    | 47                 | 1             | 34           | 5       | 0         | 101     | 2    | 134       |\n",
    "| 2  | Boston Cream Pie I             | https://www.allrecipes.com/recipe/8137/boston-... | 15        | 9             | 94          | 223    | 43                 | 1             | 26           | 5       | 0         | 97      | 2    | 95        |\n",
    "| 3  | Semi-Homemade Boston Cream Pie | https://www.allrecipes.com/recipe/278930/semi-... | 41        | 16            | 219         | 568    | 79                 | 3             | 53           | 11      | 0         | 186     | 3    | 194       |\n",
    "| 9  | Hot Milk Sponge Cake II        | https://www.allrecipes.com/recipe/8159/hot-mil... | 3         | 2             | 52          | 231    | 34                 | 0             | 20           | 4       | NaN       | 61      | 2    | 60        |\n",
    "| 17 | Boston Cream Dessert Cups      | https://www.allrecipes.com/recipe/213446/bosto... | 15        | 7             | 44          | 237    | 32                 | 0             | 22           | 3       | 0         | 41      | 1    | 101       |\n",
    "| 19 | Boston Creme Mini-Cupcakes     | https://www.allrecipes.com/recipe/220809/bosto... | 12        | 4             | 32          | 253    | 34                 | 0             | 24           | 3       | 0         | 62      | 1    | 100       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6110e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nutrition(url):\n",
    "    \"\"\" returns a dictionary of nutrition info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        nutr_dict (dict): keys are molecule types ('fat'), \n",
    "            vals are floats of quantity ('24 g' = 24)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get / extract a data frame of recipes (only name and href)\n",
    "str_query = 'boston cream pie'\n",
    "html_str = crawl_recipes(str_query)\n",
    "df_recipe = extract_recipes(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae76b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allrecipes.com/recipe/220942/chef-johns-boston-cream-pie/'\n",
    "\n",
    "# get soup from url\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "nutr_dict = dict()\n",
    "nutr_list = soup.find_all('span', class_ = 'mntl-nutrition-facts-label__nutrient-name mntl-nutrition-facts-label__nutrient-name--has-postfix')\n",
    "for fact in nutr_list:\n",
    "    nutr_feat = fact.next_sibling.strip()\n",
    "    # strip units\n",
    "    for str_rm in ['mg', 'g']:\n",
    "        if nutr_feat.endswith(str_rm):\n",
    "            nutr_feat = nutr_feat[:-len(str_rm)]\n",
    "            \n",
    "    nutr_dict[fact.text] = float(nutr_feat)\n",
    "    \n",
    "nutr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5b2fc",
   "metadata": {},
   "source": [
    "Some recipes will not have nutrition facts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a071549",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.allrecipes.com/gallery/most-popular-dessert-from-each-state/'\n",
    "\n",
    "# get soup from url\n",
    "html2 = requests.get(url2).text\n",
    "soup2 = BeautifulSoup(html2)\n",
    "\n",
    "nutr_dict2 = dict()\n",
    "nutr_list2 = soup2.find_all('span', class_ = 'mntl-nutrition-facts-label__nutrient-name mntl-nutrition-facts-label__nutrient-name--has-postfix')\n",
    "for fact in nutr_list2:\n",
    "    nutr_feat = fact.next_sibling.strip()\n",
    "    # strip units\n",
    "    for str_rm in ['mg', 'g']:\n",
    "        if nutr_feat.endswith(str_rm):\n",
    "            nutr_feat = nutr_feat[:-len(str_rm)]\n",
    "            \n",
    "    nutr_dict2[fact.text] = float(nutr_feat)\n",
    "    \n",
    "nutr_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nutr_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8489c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nutrition(url):\n",
    "    \"\"\" returns a dictionary of nutrition info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        nutr_dict (dict): keys are molecule types ('fat'), \n",
    "            vals are floats of quantity ('24 g' = 24)\n",
    "    \"\"\"\n",
    "\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    nutr_dict = dict()\n",
    "    nutr_list = soup.find_all('span', class_ = 'mntl-nutrition-facts-label__nutrient-name mntl-nutrition-facts-label__nutrient-name--has-postfix')\n",
    "    for fact in nutr_list:\n",
    "        nutr_feat = fact.next_sibling.strip()\n",
    "        # strip units\n",
    "        for str_rm in ['mg', 'g']:\n",
    "            if nutr_feat.endswith(str_rm):\n",
    "                nutr_feat = nutr_feat[:-len(str_rm)]\n",
    "            \n",
    "        nutr_dict[fact.text] = float(nutr_feat)\n",
    "    \n",
    "    return nutr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_nutrition(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b47758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get / extract a data frame of recipes (only name and href)\n",
    "str_query = 'boston cream pie'\n",
    "html_str = crawl_recipes(str_query)\n",
    "df_recipe = extract_recipes(html_str)\n",
    "\n",
    "for row_idx in range(df_recipe.shape[0]):\n",
    "    # get / extract nutrition info for a particular recipe\n",
    "    recipe_url = df_recipe.loc[row_idx, 'href']\n",
    "    nutr_dict = extract_nutrition(recipe_url)\n",
    "    \n",
    "    # add each new nutrition feature to the dataframe\n",
    "    # only if there ARE nutrition features\n",
    "    if len(nutr_dict) != 0:\n",
    "        for nutr_feat, nutr_val in nutr_dict.items():\n",
    "            df_recipe.loc[row_idx, nutr_feat] = nutr_val\n",
    "    else:\n",
    "        df_recipe = df_recipe.drop(row_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43845b78",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "- get list of dictionaries corresponding to recipes (done!)\n",
    "- get dictionary of nutrition info per recipe (done!)\n",
    "- aggregating info into dataframe (see below)\n",
    "- scatter plot (up next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_recipe(str_query, recipe_limit=None):\n",
    "    \"\"\" searches for recipes and returns list, with nutrition info\n",
    "    \n",
    "    Args:\n",
    "        str_query (str): search string\n",
    "        recipe_limit (int): if passed, limits recipe (helpful\n",
    "            to speed up nutrition scraping for teaching!)\n",
    "        \n",
    "    Returns:\n",
    "        df_recipe (pd.DataFrame): dataframe, each row is recipe.\n",
    "            includes columns href, name, and nutrition facts\n",
    "    \"\"\"    \n",
    "    # get / extract a data frame of recipes (only name and href)\n",
    "    html_str = crawl_recipes(str_query)\n",
    "    df_recipe = extract_recipes(html_str)\n",
    "    \n",
    "    if recipe_limit is not None:\n",
    "        # discard all but first few recipes\n",
    "        df_recipe = df_recipe.iloc[:recipe_limit, :]\n",
    "\n",
    "    for row_idx in range(df_recipe.shape[0]):\n",
    "        # get / extract nutrition info for a particular recipe\n",
    "        recipe_url = df_recipe.loc[row_idx, 'href']\n",
    "        nutr_dict = extract_nutrition(recipe_url)\n",
    "        \n",
    "        # add each new nutrition feature to the dataframe\n",
    "        # only if there ARE nutrition features\n",
    "        if len(nutr_dict) != 0:\n",
    "            for nutr_feat, nutr_val in nutr_dict.items():\n",
    "                df_recipe.loc[row_idx, nutr_feat] = nutr_val\n",
    "        else:\n",
    "            df_recipe = df_recipe.drop(row_idx, axis=0)\n",
    "\n",
    "    return df_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = ['pickles', 'truffles', 'peanut butter']\n",
    "\n",
    "big_df_recipe = pd.DataFrame()\n",
    "for str_query in query_list:\n",
    "    # get recipes\n",
    "    df_recipe_query = get_df_recipe(str_query)\n",
    "    \n",
    "    # record the query used to search for these recipes & aggregate\n",
    "    df_recipe_query['query'] = str_query\n",
    "    big_df_recipe = big_df_recipe.append(df_recipe_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d69c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(data_frame=big_df_recipe, x='Calcium', y='Potassium', color='query', hover_data=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5915c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
