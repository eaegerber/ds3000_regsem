{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52a63c5-8632-42cf-a598-1f9b9fcf118e",
   "metadata": {},
   "source": [
    "# Lab 1 (Due @ by 11:59 pm via Canvas/Gradescope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca321b-3edd-4428-8109-d473e4b6d195",
   "metadata": {},
   "source": [
    "#! snip: Lab1\n",
    "# $\\color{red}{\\text{SOLUTIONS}}$ \n",
    "#! snip-end\n",
    "\n",
    "Due: Tuesday Sep 26 @ 11:59 PM EST\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to Gradescope (this can also be done via the assignment on Canvas).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh `Kernel > Restart & Run All` just before uploading the `ipynb` file to gradescope.\n",
    "\n",
    "### Group Work\n",
    "\n",
    "You are encouraged to work in groups for this Lab, however each student should submit their own notebook file to Gradescope. While each Part of the Lab depends on previous parts, talking through the problem with your group should help speed up both understanding and arriving at a solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2cf95c-20bd-40b3-ac5b-aba78fa7eef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snip-copied: Lab1.ipynb\n"
     ]
    }
   ],
   "source": [
    "#! snip: Lab1\n",
    "\n",
    "!python3 -m snip_copy Lab1_Solutions.ipynb\n",
    "\n",
    "#! snip-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128c2500-de83-4732-a3ac-78ccdd6094f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will use the below modules on this lab\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197c58c-8285-446e-bb07-347de63ce276",
   "metadata": {},
   "source": [
    "## Part 1: Web Scraping Warm-Up (20 points)\n",
    "\n",
    "Build a `df_premier` which contains the names and stadiums of all the current English Premier League Teams based [on this website](https://www.premierleague.com/clubs):\n",
    "\n",
    "    df_premier.head()\n",
    "    \n",
    "yields an output:\n",
    "\n",
    "| name                   | stadium                 |\n",
    "|------------------------|-------------------------|\n",
    "| Arsenal                | Emirates Stadium        |\n",
    "| Aston Villa            | Villa Park              |\n",
    "| AFC Bournemouth        | Vitality Stadium        |\n",
    "| Brentford              | Gtech Community Stadium |\n",
    "| Brighton & Hove Albion | Amex Stadium            |\n",
    "\n",
    "Make sure you: \n",
    "- use BeautifulSoup\n",
    "- print the `.head()` of the data frame when you are finished\n",
    "\n",
    "**Hint:** there should only be two `class_` values you need to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8320bfe-d77c-4b10-a59c-c7b4c046d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! snip: Lab1\n",
    "\n",
    "# Get the html string from the class website url\n",
    "url = 'https://www.premierleague.com/clubs'\n",
    "html_str = requests.get(url).text\n",
    "\n",
    "#! snip-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043a4c21-897b-4281-b9ab-668f880ea08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stadium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Emirates Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Villa Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFC Bournemouth</td>\n",
       "      <td>Vitality Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brentford</td>\n",
       "      <td>Gtech Community Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brighton &amp; Hove Albion</td>\n",
       "      <td>Amex Stadium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                  stadium\n",
       "0                 Arsenal         Emirates Stadium\n",
       "1             Aston Villa               Villa Park\n",
       "2         AFC Bournemouth         Vitality Stadium\n",
       "3               Brentford  Gtech Community Stadium\n",
       "4  Brighton & Hove Albion             Amex Stadium"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! snip: Lab1\n",
    "\n",
    "# Build soup object from html string\n",
    "soup = BeautifulSoup(html_str)\n",
    "\n",
    "# Initialize dictionary\n",
    "premier_dict = {'name': [],\n",
    "                'stadium': []}\n",
    "\n",
    "for name in soup.find_all(class_='name'):\n",
    "    premier_dict['name'].append(name.text)\n",
    "    \n",
    "for stad in soup.find_all(class_='club-card__stadium'):\n",
    "    premier_dict['stadium'].append(stad.text)\n",
    "\n",
    "df_premier = pd.DataFrame.from_dict(premier_dict)\n",
    "df_premier.head()\n",
    "\n",
    "#! snip-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714b998-d20c-4119-a463-38c180001261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae31e8-5794-4815-86b6-2e50ea06a05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c384e097-798c-4462-a6d0-329e37b4ceb0",
   "metadata": {},
   "source": [
    "# Part 2: A Trickier Web Scraper\n",
    "\n",
    "For this problem, we will (together) create a small data set scraped from [flightaware.com](https://flightaware.com/) which includes some details from the current flight schedule at Boston Logan Airport. You will build the first two parts of the data pipeline as functions (Parts 2.1 and 2.2) and then provide a detailed overview/description of the last two parts of the pipeline based on code I have written/provided (Parts 2.3 and 2.4). Please do not take these final two parts lightly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b6eb5-bf20-4a91-9967-f78fe2f8c80f",
   "metadata": {},
   "source": [
    "## Part 2.1: The Scraper Function (20 points)\n",
    "\n",
    "Complete the function `get_airport_html()` below (including docstring) which visits the url of a given US airport code and grabs the html. Visit [flightaware.com](https://flightaware.com/) and type in a few codes (e.g. BOS, JFK, LAX, RDU) and notice the pattern in the url so that you can pass any airport code to the function as a string. **Make sure to remove the `pass` statement when you are finished**. I have written the code you should run once the function is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f8cca2-7c10-4e29-8c8c-061044eb0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_html(code):\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0611e7f9-3b60-41be-8ee6-6f663a45b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! snip: Lab1\n",
    "\n",
    "def get_airport_html(code):\n",
    "    \"\"\" a function that scrapes the flightaware website\n",
    "\n",
    "    Args:\n",
    "        code (str): a string with the airport code\n",
    "\n",
    "    Returns:\n",
    "        html_text (str): the html text from scraping the website\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f'https://flightaware.com/live/airport/K{code}'\n",
    "    html_text = requests.get(url).text\n",
    "    \n",
    "    return html_text\n",
    "\n",
    "#! snip-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142e684f-b455-49f4-8784-4959cffa76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you are done the following code should be run\n",
    "url_text = get_airport_html('BOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfca310-6271-45d6-9d1d-ee5caf2d0115",
   "metadata": {},
   "source": [
    "## Part 2.2: The Soup Function (20 points)\n",
    "\n",
    "Complete the function `get_airport_table_soup()` below (including docstring) which takes the html from the previous function and outputs one of four beautiful soup objects, depending on the board you are interested in as defined by the `'id'` attribute:\n",
    "\n",
    "    - `id='arrivals-board'`\n",
    "    - `id='departures-board'`\n",
    "    - `id='enroute-board'`\n",
    "    - `id='scheduled-board'`\n",
    "    \n",
    "The function should take two arguments: the html object from `get_airport_html()` and a string that specifies the `id` you are interested in (by default, the arrivals board).\n",
    "    \n",
    "**Make sure to remove the `pass` statement when you are finished.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d13b576-7447-472a-aa67-389412a173a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_table_soup(html, board):\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9895e39-ecbd-4bb7-ae30-929226f3fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! snip: Lab1\n",
    "\n",
    "def get_airport_table_soup(html, board):\n",
    "    \"\"\" gets the board soup for a given board and the html text\n",
    "\n",
    "    Args:\n",
    "        html (str): a string of html text (the output from get_airport_html)\n",
    "        board (str): a string for one of the four board ids\n",
    "\n",
    "    Returns:\n",
    "        soup (soup): a soup object for the corresponding board\n",
    "    \"\"\"\n",
    "    \n",
    "    big_soup = BeautifulSoup(html)\n",
    "    soup = big_soup.find_all(id=board)[0]\n",
    "    \n",
    "    return soup\n",
    "\n",
    "#! snip-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559b9aa7-bc87-43d0-a7fa-17bbb4f1b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you are done the following code should be run (feel free to change the board if you wish)\n",
    "board_choice = 'arrivals-board'\n",
    "my_board_soup = get_airport_table_soup(url_text, board_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981fb10-b741-4251-9806-32ba3e15248f",
   "metadata": {},
   "source": [
    "## Part 2.3: Cleaning The Board (20 points)\n",
    "\n",
    "Below is the function `clean_board_df()`, which takes the soup object from the previous function and creates a data frame with the following columns:\n",
    "\n",
    "    - `flight number`: the flight number\n",
    "    - `aircraft type`: the type of aircraft\n",
    "    - `airport name`: the name of the originating/destination airport (depending on type of board)\n",
    "    - `airport code`: the letter code of the originating/destination airport\n",
    "    - `departure time`: the time of the flight's departure\n",
    "    - `arrival time`: the time of the flight's arrival\n",
    "\n",
    "I have written the function and (given your function from Part 2.2 works) it should work. **DO NOT CHANGE ANYTHING IN THE BODY OF THE FUNCTION.**\n",
    "\n",
    "**In a markdown cell** create a bullet point list where you explain each what each chunk of code does. Your bullet point list should have **FOUR** bullet points/explanations corresponding to the four chunks below the `# EXPLAIN THIS (number)` comments. You must accurately summarize the content of each code chunk. **Talking to your neighbors/group about this is highly recommended.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a65092-fc8a-41bb-9de3-ac4deb703097",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 70\u001b[0m\n\u001b[0;32m     66\u001b[0m     clean_board_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(clean_board_dict)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clean_board_df\n\u001b[1;32m---> 70\u001b[0m clean_df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_board_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_board_soup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m clean_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[11], line 66\u001b[0m, in \u001b[0;36mclean_board_df\u001b[1;34m(soup)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# EXPLAIN THIS (4)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m clean_board_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight number\u001b[39m\u001b[38;5;124m'\u001b[39m: flight_number,\n\u001b[0;32m     61\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maircraft type\u001b[39m\u001b[38;5;124m'\u001b[39m: aircraft_type,\n\u001b[0;32m     62\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mairport name\u001b[39m\u001b[38;5;124m'\u001b[39m: airport_name,\n\u001b[0;32m     63\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mairport code\u001b[39m\u001b[38;5;124m'\u001b[39m: airport_code,\n\u001b[0;32m     64\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeparture time\u001b[39m\u001b[38;5;124m'\u001b[39m: departure_time,\n\u001b[0;32m     65\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrival time\u001b[39m\u001b[38;5;124m'\u001b[39m: arrival_time}\n\u001b[1;32m---> 66\u001b[0m clean_board_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_board_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_board_df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:1816\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1810\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1811\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1812\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1813\u001b[0m     )\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1818\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    730\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    731\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "def clean_board_df(soup):    \n",
    "    \"\"\" takes the soup of a board and cleans it, creating a data frame\n",
    "\n",
    "    Args:\n",
    "        soup (soup): the soup from get_airport_table_soup\n",
    "\n",
    "    Returns:\n",
    "        clean_board_df (data frame): a data frame with six columns corresponding to\n",
    "            flight number\n",
    "            aircraft type\n",
    "            airport name\n",
    "            airport code\n",
    "            departure time\n",
    "            arrival time\n",
    "    \"\"\"\n",
    "    \n",
    "    # EXPLAIN THIS (1)\n",
    "    names = soup.find_all('span', attrs = {'title':True})\n",
    "    flight_number = []\n",
    "    aircraft_type = []\n",
    "    airport_name = []\n",
    "    for idx in range(0, len(names), 3):\n",
    "        flight_number.append(names[idx].text)\n",
    "        aircraft_type.append(names[idx+1].text)\n",
    "        airport_name.append(names[idx+2].text)\n",
    "\n",
    "    # EXPLAIN THIS (2)\n",
    "    codes = soup.find_all(attrs = {'dir': 'ltr'})\n",
    "    airport_code = []\n",
    "    for idx in range(0, len(codes), 2):\n",
    "        airport_code.append(codes[idx+1].text.replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "    # EXPLAIN THIS (3)\n",
    "    times = soup.find_all(class_='tz')\n",
    "    departure_time = []\n",
    "    arrival_time = []\n",
    "    for idx in range(0, len(times), 2):\n",
    "        dep_split_string = times[idx].previous_sibling.split('\\xa0')\n",
    "        arr_split_string = times[idx+1].previous_sibling.split('\\xa0')\n",
    "        \n",
    "        if dep_split_string[0].endswith('a') == True:\n",
    "            dep_datetime_str = dep_split_string[0][:-1] + ' AM'\n",
    "            dep_datetime_time = datetime.strptime(dep_datetime_str, '%I:%M %p').time()\n",
    "            departure_time.append(dep_datetime_time)\n",
    "        else:\n",
    "            dep_datetime_str = dep_split_string[0][:-1] + ' PM'\n",
    "            dep_datetime_time = datetime.strptime(dep_datetime_str, '%I:%M %p').time()\n",
    "            departure_time.append(dep_datetime_time)\n",
    "        \n",
    "        if arr_split_string[0].endswith('a') == True:\n",
    "            arr_datetime_str = arr_split_string[0][:-1] + ' AM'\n",
    "            arr_datetime_time = datetime.strptime(arr_datetime_str, '%I:%M %p').time()\n",
    "            arrival_time.append(arr_datetime_time)\n",
    "        else:\n",
    "            arr_datetime_str = arr_split_string[0][:-1] + ' PM'\n",
    "            arr_datetime_time = datetime.strptime(arr_datetime_str, '%I:%M %p').time()\n",
    "            arrival_time.append(arr_datetime_time)\n",
    "\n",
    "    # EXPLAIN THIS (4)\n",
    "    clean_board_dict = {'flight number': flight_number,\n",
    "                        'aircraft type': aircraft_type,\n",
    "                        'airport name': airport_name,\n",
    "                        'airport code': airport_code,\n",
    "                        'departure time': departure_time,\n",
    "                        'arrival time': arrival_time}\n",
    "    clean_board_df = pd.DataFrame.from_dict(clean_board_dict)\n",
    "    \n",
    "    return clean_board_df\n",
    "    \n",
    "clean_df = clean_board_df(my_board_soup)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4d6c7-c376-4840-b673-54d0d1bd28f8",
   "metadata": {},
   "source": [
    "Your answer in this cell:\n",
    "- Explain Code Chunk 1:\n",
    "- Explain Code Chunk 2:\n",
    "- Explain Code Chunk 3:\n",
    "- Explain Code Chunk 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576fd51-5d33-4d39-8f28-5e55b1611be5",
   "metadata": {},
   "source": [
    "## Part 2.4: Grabbing More Data (20 points)\n",
    "\n",
    "Below (already written for you) is the function `get_aircraft_info()` which cycles through the different aircraft types in the data frame from the previous part and adds a column with a count of the number of aircrafts currently operating of that type. **DO NOT CHANGE ANYTHING IN THE BODY OF THE FUNCTION.**\n",
    "\n",
    "**In a markdown cell** explain in why we were able to use `pd.read_html()` instead of `requests.get()` and comment on the values in the new column; is there something off about them?\n",
    "\n",
    "**Hint:** you may want to take a look at an example url in your browser.\n",
    "\n",
    "**Note:** I occasionally got an HTTPS error when running this; just wait a minute and try again, it should eventually work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a287ea9-7e7a-402d-8457-af23a7e0b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aircraft_info(clean_df):\n",
    "    \"\"\" takes a data frame of an aircraft board and adds a column with count of aircraft types\n",
    "\n",
    "    Args:\n",
    "        clean_df (data frame): the output of clean_board_df\n",
    "\n",
    "    Returns:\n",
    "        clean_df (data frame): the same data frame, but with an extra column\n",
    "    \"\"\"\n",
    " \n",
    "    # get a list of aircraft types from the initial data frame\n",
    "    aircraft_type = list(clean_df['aircraft type'])\n",
    "\n",
    "    #initialize an empty list to count the number of each type\n",
    "    num_type = []\n",
    "\n",
    "    # loop through the different types\n",
    "    for idx in range(len(aircraft_type)):\n",
    "\n",
    "        # get the url for each type\n",
    "        craft_url = f'https://flightaware.com/live/aircrafttype/{aircraft_type[idx]}'\n",
    "\n",
    "        # grab the table from the url\n",
    "        craft_tables = pd.read_html(craft_url)\n",
    "\n",
    "        # add the info from the table to the list\n",
    "        num_type.append(craft_tables[2].shape[0])\n",
    "\n",
    "    # turn the list into a series and add it to the data frame\n",
    "    clean_df['num type'] = pd.Series(num_type)\n",
    "\n",
    "    # return the updated data frame\n",
    "    return clean_df\n",
    "\n",
    "final_df = get_aircraft_info(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24455bd-fa20-46c0-8d54-f4b02349f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14b40c-218d-46fa-a2e8-b86527996cba",
   "metadata": {},
   "source": [
    "Your answer in this cell:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
